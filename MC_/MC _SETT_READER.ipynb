{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import re\n",
    "# ---------------- CONFIGURATION ----------------\n",
    "SOURCE_FOLDER = r\"E:\\\\Automation\\\\Card_recon\\\\original reports\"   # change this\n",
    "LOG_FILE = \"conversion.log\"\n",
    "MIN_TEXT_RATIO = 0.75           # heuristic threshold\n",
    "# -----------------------------------------------\n",
    "\n",
    "\n",
    "# ---------------- LOGGING SETUP ----------------\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "logging.info(\"===== Conversion started =====\")\n",
    "# -----------------------------------------------\n",
    "\n",
    "\n",
    "def is_likely_text(data: bytes) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristic check:\n",
    "    If most bytes are printable ASCII or whitespace,\n",
    "    treat file as text.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return False\n",
    "\n",
    "    printable = sum(\n",
    "        1 for b in data\n",
    "        if 32 <= b <= 126 or b in (9, 10, 13)\n",
    "    )\n",
    "\n",
    "    ratio = printable / len(data)\n",
    "    return ratio >= MIN_TEXT_RATIO\n",
    "\n",
    "\n",
    "def convert_file(input_path: str):\n",
    "    base, _ = os.path.splitext(input_path)\n",
    "    output_path = base + \".txt\"\n",
    "\n",
    "    with open(input_path, \"rb\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    # Integrity check\n",
    "    if len(raw) == 0:\n",
    "        logging.warning(f\"Empty file skipped: {input_path}\")\n",
    "        return\n",
    "\n",
    "    # Reconstruction detection\n",
    "    if not is_likely_text(raw):\n",
    "        logging.warning(\n",
    "            f\"Binary or archive split detected. \"\n",
    "            f\"Reconstruction required: {input_path}\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Decode safely\n",
    "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as out:\n",
    "        out.write(text)\n",
    "\n",
    "    logging.info(f\"Converted: {input_path} -> {output_path}\")\n",
    "    print(f\"âœ” Converted: {os.path.basename(input_path)}\")\n",
    "\n",
    "\n",
    "def convert_folder(folder_path: str):\n",
    "    files = [f for f in os.listdir(folder_path) if f.lower().endswith(\".001\")]\n",
    "\n",
    "    if not files:\n",
    "        print(\"No .001 files found.\")\n",
    "        return\n",
    "\n",
    "    total = len(files)\n",
    "    print(f\"Found {total} .001 files\\n\")\n",
    "\n",
    "    for index, filename in enumerate(files, start=1):\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        print(f\"[{index}/{total}] Processing {filename}...\")\n",
    "        convert_file(full_path)\n",
    "\n",
    "    print(\"\\nConversion completed.\")\n",
    "\n",
    "\n",
    "# -------------------- RUN ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.isdir(SOURCE_FOLDER):\n",
    "        raise FileNotFoundError(\"Source folder does not exist\")\n",
    "\n",
    "    convert_folder(SOURCE_FOLDER)\n",
    "    logging.info(\"===== Conversion finished =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c30a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure file paths via environment variables or defaults\n",
    "BASE_DIR = Path(os.environ.get('MC_BASE_DIR', r'E:\\\\Automation\\\\Card_recon\\\\original reports'))\n",
    "LOE_FILE = Path(os.environ.get('MC_LOE_FILE', 'LOE20250219.xlsx'))\n",
    "OUTGOING_FILE = Path(os.environ.get('MC_OUT_FILE', 'All Outgoing Transaction Details TWI_2025_02_20_080441.xlsx'))\n",
    "MC_SETT_FILE = Path(os.environ.get('MC_SETT_DIR','output.txt'))\n",
    "LOE_PATH = BASE_DIR / LOE_FILE\n",
    "OUTGOING_PATH = BASE_DIR / OUTGOING_FILE\n",
    "MC_SETT_PATH = BASE_DIR / MC_SETT_FILE\n",
    "# Logging setup: file + console. Log filename can be overridden with MC_LOG_FILE env var.\n",
    "LOG_FILE = Path(os.environ.get('MC_LOG_FILE', f'conversion.log'))\n",
    "LOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s', handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler(sys.stdout)])\n",
    "logger = logging.getLogger(__name__)\n",
    "# Output directory for reports (override with MC_OUTPUT_DIR env var)\n",
    "OUTPUT_DIR = Path(os.environ.get('MC_OUTPUT_DIR', r'E:\\\\Automation\\\\Card_recon\\\\MC_\\\\mc_reports'))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "logger.info(f'Configured paths: LOE_PATH={LOE_PATH} OUTGOING_PATH={OUTGOING_PATH} LOG_FILE={LOG_FILE} OUTPUT_DIR={OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dba144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settlement-only verification (safe parser)\n",
    "logger.info('Running settlement-only read to verify parsing of MC_SETT_PATH (no LOE/Outgoing re-read)')\n",
    "mc_settl = pd.DataFrame()\n",
    "if MC_SETT_PATH.exists():\n",
    "    parsed = False\n",
    "    for sep,name in [('\t','TSV'), ('|','PIPE'), (',','CSV')]:\n",
    "        try:\n",
    "            mc_settl = pd.read_csv(str(MC_SETT_PATH), sep=sep, engine='python')\n",
    "            logger.info(f'Read MC settlement as {name}: {MC_SETT_PATH} (shape={mc_settl.shape})')\n",
    "            parsed = True\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "    if not parsed:\n",
    "        try:\n",
    "            mc_settl = pd.read_fwf(str(MC_SETT_PATH))\n",
    "            logger.info(f'Read MC settlement as fixed-width: {MC_SETT_PATH} (shape={mc_settl.shape})')\n",
    "        except Exception:\n",
    "            logger.exception(f'Failed to parse MC settlement file: {MC_SETT_PATH}')\n",
    "            mc_settl = pd.DataFrame()\n",
    "else:\n",
    "    logger.warning(f'MC settlement not found: {MC_SETT_PATH}')\n",
    "print('mc_settl shape:', getattr(mc_settl, 'shape', None))\n",
    "try:\n",
    "    display(mc_settl.head())\n",
    "except Exception:\n",
    "    print(mc_settl.head().to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse settlement blocks: extract header fields and transaction rows, save parsed CSVs\n",
    "logger.info('Extracting headers and transactions from MC settlement')\n",
    "from pathlib import Path\n",
    "out_dir = OUTPUT_DIR / 'mc_settl_parsed'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "# obtain raw text from the settlement file (prefer original file)\n",
    "if MC_SETT_PATH.exists():\n",
    "    txt = MC_SETT_PATH.read_text(errors='ignore')\n",
    "elif 'mc_settl' in globals():\n",
    "    try:\n",
    "        txt = mc_settl.to_string()\n",
    "    except Exception:\n",
    "        txt = ''\n",
    "else:\n",
    "    txt = ''\n",
    "if not txt:\n",
    "    logger.warning('No settlement text available to parse')\n",
    "# split into report blocks using report id markers (accept optional -AA)\n",
    "reports = re.split(r'(?=(1IP727010(?:-AA)?|1IP727020))', txt)\n",
    "all_rows = []\n",
    "block_idx = 0\n",
    "for rep in reports:\n",
    "    if not rep or not rep.strip():\n",
    "        continue\n",
    "    block_idx += 1\n",
    "    report_text = rep\n",
    "    # header fields\n",
    "    def _g(pattern):\n",
    "        m = re.search(pattern, report_text, re.IGNORECASE)\n",
    "        return m.group(1).strip() if m else ''\n",
    "    accept_brand = _g(r'ACCEPTANCE BRAND:\\s*(.+)')\n",
    "    run_date = _g(r'RUN DATE:\\s*([0-9/]+)')\n",
    "    bs_level = _g(r'BUSINESS SERVICE LEVEL:\\s*([A-Z0-9-]+)')\n",
    "    bs_id = _g(r'BUSINESS SERVICE ID:\\s*([0-9A-Z-]+)')\n",
    "    file_id = _g(r'FILE ID:\\s*([0-9/]+)')\n",
    "    member_id = _g(r'MEMBER ID:\\s*([0-9A-Z-]+)')\n",
    "    # find subtotal line for this business service id (if present)\n",
    "    subtotal_match = re.search(r'BUSINESS SERVICE ID SUBTOTAL\\s+([0-9,]+)\\s+([-0-9,]+\\.\\d{2})\\s*(CR|DR)?', report_text, re.IGNORECASE)\n",
    "    subtotal_counts = subtotal_match.group(1).replace(',','') if subtotal_match else ''\n",
    "    subtotal_amount = subtotal_match.group(2).replace(',','') if subtotal_match else ''\n",
    "    # parse transaction table lines: look for lines containing a numeric amount pattern\n",
    "    rows = []\n",
    "    for ln in report_text.splitlines():\n",
    "        ln_str = ln.strip()\n",
    "        if not ln_str:\n",
    "            continue\n",
    "        # match lines with an amount like 10,202.21\n",
    "        amt_matches = re.findall(r'[-0-9,]+\\.\\d{2}', ln)\n",
    "        if not amt_matches:\n",
    "            continue\n",
    "        # attempt to find counts (an integer before the first amount)\n",
    "        cnt_m = re.search(r'(\\d+)\\s+[-0-9,]+\\.\\d{2}', ln)\n",
    "        counts = int(cnt_m.group(1).replace(',','')) if cnt_m else None\n",
    "        recon_amount = float(amt_matches[0].replace(',','')) if len(amt_matches) >= 1 else None\n",
    "        fee_amount = float(amt_matches[1].replace(',','')) if len(amt_matches) >= 2 else None\n",
    "        # try to capture CR/DR indicators for recon and fee\n",
    "        recon_sign = None\n",
    "        fee_sign = None\n",
    "        s_recon = re.search(r'([-0-9,]+\\.\\d{2})\\s+(CR|DR)', ln)\n",
    "        if s_recon:\n",
    "            recon_sign = s_recon.group(2)\n",
    "        s_fee = re.search(r'([-0-9,]+\\.\\d{2}).*(CR|DR)\\s*$', ln)\n",
    "        if s_fee:\n",
    "            fee_sign = s_fee.group(2)\n",
    "        # description / label (first 40 chars)\n",
    "        label = ln[:40].strip()\n",
    "        row = {\n",
    "            'block_id': block_idx,\n",
    "            'accept_brand': accept_brand,\n",
    "            'run_date': run_date,\n",
    "            'bs_level': bs_level,\n",
    "            'bs_id': bs_id,\n",
    "            'file_id': file_id,\n",
    "            'member_id': member_id,\n",
    "            'label': label,\n",
    "            'counts': counts,\n",
    "            'recon_amount': recon_amount,\n",
    "            'recon_sign': recon_sign,\n",
    "            'fee_amount': fee_amount,\n",
    "            'fee_sign': fee_sign,\n",
    "        }\n",
    "        rows.append(row)\n",
    "    # save per-block CSV if any rows found\n",
    "    if rows:\n",
    "        df_blk = pd.DataFrame(rows)\n",
    "        blk_file = out_dir / f'block_{block_idx:03d}_bs{bs_id}.csv'\n",
    "        #df_blk.to_csv(blk_file, index=False)\n",
    "        #logger.info(f'Wrote parsed block file: {blk_file}')\n",
    "        all_rows.extend(rows)\n",
    "    else:\n",
    "        logger.info(f'No transaction rows parsed for block {block_idx} (bs_id={bs_id})')\n",
    "# combined CSV\n",
    "if all_rows:\n",
    "    df_all = pd.DataFrame(all_rows)\n",
    "    combined = out_dir / 'mc_settl_parsed_combined.csv'\n",
    "    df_all.to_csv(combined, index=False)\n",
    "    logger.info(f'Wrote combined parsed CSV: {combined}')\n",
    "else:\n",
    "    logger.warning('No parsed rows extracted from settlement text')\n",
    "# also write a simple summary file for subtotals if available\n",
    "summary_lines = []\n",
    "for rep in reports:\n",
    "    if 'BUSINESS SERVICE ID SUBTOTAL' in rep.upper():\n",
    "        m = re.search(r'BUSINESS SERVICE ID SUBTOTAL\\s+([0-9,]+)\\s+([-0-9,]+\\.\\d{2})', rep, re.IGNORECASE)\n",
    "        if m:\n",
    "            summary_lines.append({'subtotal_counts': m.group(1).replace(',',''), 'subtotal_amount': m.group(2).replace(',','')})\n",
    "if summary_lines:\n",
    "    pd.DataFrame(summary_lines).to_csv(out_dir / 'bsid_subtotals.csv', index=False)\n",
    "    logger.info('Wrote BUSINESS SERVICE ID SUBTOTAL file')\n",
    "print('Parsing complete. Inspect', out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caadee2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065be41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
